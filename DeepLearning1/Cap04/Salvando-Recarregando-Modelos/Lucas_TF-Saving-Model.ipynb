{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T12:01:24.162566Z",
     "start_time": "2020-12-27T12:01:24.146848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the graph\n",
    "import tensorflow as tf \n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import tensorflow as tf\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "\n",
    "##########################\n",
    "### Definindo o Modelo\n",
    "##########################\n",
    "\n",
    "# Função que define uma camada\n",
    "def fc_layer(input_tensor,\n",
    "             n_output_units,\n",
    "             name,\n",
    "             activation_fn = None,\n",
    "             seed = None,\n",
    "             weight_params = None,\n",
    "             bias_params = None):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(name):\n",
    "\n",
    "        if weight_params is not None:\n",
    "            weights = tf.constant(weight_params, name = 'weights', dtype = tf.float32)\n",
    "        else:\n",
    "            weights = tf.Variable(tf.random.truncated_normal(\n",
    "                shape=[input_tensor.get_shape().as_list()[-1], n_output_units],\n",
    "                    mean = 0.0,\n",
    "                    stddev = 0.1,\n",
    "                    dtype = tf.float32,\n",
    "                    seed = seed),\n",
    "                name = 'weights',)\n",
    "\n",
    "        if bias_params is not None:\n",
    "            biases = tf.constant(bias_params, name = 'biases', dtype=tf.float32)\n",
    "\n",
    "        else:\n",
    "            biases = tf.Variable(tf.zeros(shape = [n_output_units]),\n",
    "                                 name = 'biases',\n",
    "                                 dtype = tf.float32)\n",
    "\n",
    "        act = tf.matmul(input_tensor, weights) + biases\n",
    "\n",
    "        if activation_fn is not None:\n",
    "            act = activation_fn(act)\n",
    "\n",
    "    return act\n",
    "\n",
    "# Função que define o grafo\n",
    "def mlp_graph(n_input = 784,\n",
    "              n_classes = 10,\n",
    "              n_hidden_1 = 128,\n",
    "              n_hidden_2 = 256,\n",
    "              learning_rate = 0.1,\n",
    "              fixed_params = None):\n",
    "\n",
    "    # Carregando pesos e bias de arquivos NumPy\n",
    "    if not fixed_params:\n",
    "        var_names = ['fc1/weights:0', 'fc1/biases:0',\n",
    "                     'fc2/weights:0', 'fc2/biases:0',\n",
    "                     'logits/weights:0', 'logits/biases:0',]\n",
    "\n",
    "        fixed_params = {v: None for v in var_names}\n",
    "        found_params = False\n",
    "    else:\n",
    "        found_params = True\n",
    "\n",
    "    # Input data\n",
    "    tf_x = tf.compat.v1.placeholder(tf.float32, [None, n_input], name = 'features')\n",
    "    tf_y = tf.compat.v1.placeholder(tf.int32, [None], name = 'targets')\n",
    "    tf_y_onehot = tf.one_hot(tf_y, depth = n_classes, name = 'onehot_targets')\n",
    "\n",
    "    # Multilayer perceptron\n",
    "    fc1 = fc_layer(input_tensor = tf_x,\n",
    "                   n_output_units = n_hidden_1,\n",
    "                   name = 'fc1',\n",
    "                   weight_params = fixed_params['fc1/weights:0'],\n",
    "                   bias_params = fixed_params['fc1/biases:0'],\n",
    "                   activation_fn = tf.nn.relu)\n",
    "\n",
    "    fc2 = fc_layer(input_tensor = fc1,\n",
    "                   n_output_units = n_hidden_2,\n",
    "                   name = 'fc2',\n",
    "                   weight_params = fixed_params['fc2/weights:0'],\n",
    "                   bias_params = fixed_params['fc2/biases:0'],\n",
    "                   activation_fn = tf.nn.relu)\n",
    "\n",
    "    logits = fc_layer(input_tensor = fc2,\n",
    "                      n_output_units = n_classes,\n",
    "                      name = 'logits',\n",
    "                      weight_params = fixed_params['logits/weights:0'],\n",
    "                      bias_params = fixed_params['logits/biases:0'],\n",
    "                      activation_fn = tf.nn.relu)\n",
    "\n",
    "    # Loss e optimizer\n",
    "    ### Somente necessário se nenhum parâmetro existente for encontrado\n",
    "    ### e um grafo treinável deve ser inicializado\n",
    "    if not found_params:\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=tf.stop_gradient(tf_y_onehot))\n",
    "        cost = tf.reduce_mean(input_tensor=loss, name='cost')\n",
    "        optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n",
    "            learning_rate=learning_rate)\n",
    "        train = optimizer.minimize(cost, name='train')\n",
    "\n",
    "    # Previsões\n",
    "    probabilities = tf.nn.softmax(logits, name = 'probabilities')\n",
    "    labels = tf.cast(tf.argmax(input=logits, axis=1), tf.int32, name = 'labels')\n",
    "\n",
    "    correct_prediction = tf.equal(labels, tf_y, name='correct_predictions')\n",
    "    accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, tf.float32), name = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T12:01:57.135303Z",
     "start_time": "2020-12-27T12:01:39.641938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 001 | AvgCost: 0.350 | Acurácia em Treino/Validação: 0.927/0.932\n",
      "Epoch: 002 | AvgCost: 0.166 | Acurácia em Treino/Validação: 0.961/0.962\n",
      "Epoch: 003 | AvgCost: 0.120 | Acurácia em Treino/Validação: 0.974/0.969\n",
      "Epoch: 004 | AvgCost: 0.095 | Acurácia em Treino/Validação: 0.977/0.970\n",
      "Epoch: 005 | AvgCost: 0.076 | Acurácia em Treino/Validação: 0.983/0.975\n",
      "Epoch: 006 | AvgCost: 0.063 | Acurácia em Treino/Validação: 0.983/0.976\n",
      "Epoch: 007 | AvgCost: 0.053 | Acurácia em Treino/Validação: 0.985/0.975\n",
      "Epoch: 008 | AvgCost: 0.045 | Acurácia em Treino/Validação: 0.989/0.979\n",
      "Epoch: 009 | AvgCost: 0.038 | Acurácia em Treino/Validação: 0.992/0.980\n",
      "Epoch: 010 | AvgCost: 0.033 | Acurácia em Treino/Validação: 0.993/0.979\n",
      "Acurácia em Teste: 0.975\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import input_data\n",
    "\n",
    "##########################\n",
    "### Configurações\n",
    "##########################\n",
    "\n",
    "# Hiperparâmetros\n",
    "learning_rate = 0.1\n",
    "training_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "##########################\n",
    "### Definição do Grafo\n",
    "##########################\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    mlp_graph()\n",
    "\n",
    "##########################\n",
    "### DATASET\n",
    "##########################\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"/media/datasets/DeepLearningI/Cap04/MNIST\", one_hot = False)\n",
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot = False)\n",
    "\n",
    "\n",
    "##########################\n",
    "### Treinamento e Avaliação\n",
    "##########################\n",
    "\n",
    "with tf.compat.v1.Session(graph = g) as sess:\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    saver0 = tf.compat.v1.train.Saver()\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run(['train', 'cost:0'], feed_dict = {'features:0': batch_x,\n",
    "                                                            'targets:0': batch_y})\n",
    "            avg_cost += c\n",
    "\n",
    "        train_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.train.images,\n",
    "                                                        'targets:0': mnist.train.labels})\n",
    "\n",
    "        valid_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.validation.images,\n",
    "                                                        'targets:0': mnist.validation.labels})\n",
    "\n",
    "        print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / (i + 1)), end=\"\")\n",
    "        print(\" | Acurácia em Treino/Validação: %.3f/%.3f\" % (train_acc, valid_acc))\n",
    "\n",
    "    test_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.test.images,\n",
    "                                                   'targets:0': mnist.test.labels})\n",
    "    print('Acurácia em Teste: %.3f' % test_acc)\n",
    "\n",
    "    ##########################\n",
    "    ### Salvando o Modelo Treinado\n",
    "    ##########################\n",
    "    saver0.save(sess, save_path = './lucas-mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T12:02:54.698875Z",
     "start_time": "2020-12-27T12:02:54.344482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from ./lucas-mlp\n",
      "Acurácia em Teste: 0.975\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import input_data\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"/media/datasets/DeepLearningI/Cap04/MNIST\", one_hot = False)\n",
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot = False)\n",
    "\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "\n",
    "    saver1 = tf.compat.v1.train.import_meta_graph('./lucas-mlp.meta')\n",
    "    saver1.restore(sess, save_path = './lucas-mlp')\n",
    "\n",
    "    test_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.test.images,\n",
    "                                                   'targets:0': mnist.test.labels})\n",
    "    print('Acurácia em Teste: %.3f' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
