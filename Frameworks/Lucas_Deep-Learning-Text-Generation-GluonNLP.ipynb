{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextRegognition with GluonCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:01:21.690833Z",
     "start_time": "2020-11-19T12:01:16.480658Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q gluonnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:07:01.587687Z",
     "start_time": "2020-11-19T12:06:59.360754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting regex\n",
      "  Downloading regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719 kB)\n",
      "\u001b[K     |████████████████████████████████| 719 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: regex\n",
      "Successfully installed regex-2020.11.13\n"
     ]
    }
   ],
   "source": [
    "!pip install -U regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:03:36.065880Z",
     "start_time": "2020-11-19T12:03:36.056053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "# https://github.com/dmlc/gluon-nlp\n",
    "import text_generation.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:05:02.515753Z",
     "start_time": "2020-11-19T12:05:02.506965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mxnet    1.7.0\n",
      "json     2.0.9\n",
      "autopep8 1.4.4\n",
      "numpy    1.18.1\n",
      "gluonnlp 0.10.0\n",
      "Data Science Academy\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:05:27.641077Z",
     "start_time": "2020-11-19T12:05:27.638313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vamos alterar o dispositivo para CPU (GPU não é necessário neste estudo de caso)\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:06:31.983472Z",
     "start_time": "2020-11-19T12:05:38.092908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab file is not found. Downloading.\n",
      "Downloading /home/lucas/.mxnet/models/2492485986095506788/2492485986095506788_openai_webtext-f917dc78.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/openai_webtext-f917dc78.zip...\n",
      "Downloading /home/lucas/.mxnet/models/gpt2_117m_openai_webtext-26416f2e.zipa24a24d8-1f33-42b1-98ba-27e7d4956595 from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/gpt2_117m_openai_webtext-26416f2e.zip...\n"
     ]
    }
   ],
   "source": [
    "# Vamos importar o modelo pré-treinado para geração de texto\n",
    "model, vocab = text_generation.model.get_model(name = 'gpt2_117m',\n",
    "                                               dataset_name = 'openai_webtext',\n",
    "                                               pretrained = True,\n",
    "                                               ctx = ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:07:08.016266Z",
     "start_time": "2020-11-19T12:07:07.412720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPE rank file is not found. Downloading.\n",
      "Downloading /home/lucas/.mxnet/models/1605787627.4260728openai_webtext_bpe_ranks-396d4d8e.json from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/openai_webtext_bpe_ranks-396d4d8e.zip...\n"
     ]
    }
   ],
   "source": [
    "# Criamos então o tokenizador\n",
    "tokenizer = nlp.data.GPT2BPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:07:19.209574Z",
     "start_time": "2020-11-19T12:07:19.207310Z"
    }
   },
   "outputs": [],
   "source": [
    "# E também o objeto para remover a tokenização (usaremos para mostrar o texto gerado)\n",
    "detokenizer = nlp.data.GPT2BPEDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:07:34.393209Z",
     "start_time": "2020-11-19T12:07:34.389460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Definimos o token de final de texto\n",
    "eos_id = vocab[vocab.eos_token]\n",
    "print(vocab.eos_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:26.248575Z",
     "start_time": "2020-11-19T12:18:26.245635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Esta string será usada como ponto de partida para a geração de texto\n",
    "bos_str = 'School Teacher and students'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:28.314977Z",
     "start_time": "2020-11-19T12:18:28.312432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adicionamos um espaço no início da string\n",
    "if not bos_str.startswith(' '):\n",
    "    bos_str = ' ' + bos_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:28.751608Z",
     "start_time": "2020-11-19T12:18:28.748873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizamos a string\n",
    "bos_tokens = tokenizer(bos_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:29.434810Z",
     "start_time": "2020-11-19T12:18:29.431809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ĠSchool', 'ĠTeacher', 'Ġand', 'Ġstudents']\n"
     ]
    }
   ],
   "source": [
    "# Geramos o vocabulário com os tokens\n",
    "bos_ids = vocab[bos_tokens]\n",
    "print(bos_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:30.154266Z",
     "start_time": "2020-11-19T12:18:30.150747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classe para o decoder\n",
    "class GPT2Decoder(text_generation.model.LMDecoder):\n",
    "    def __call__(self, inputs, states):\n",
    "        \n",
    "        # Recebe os inputs\n",
    "        inputs = inputs.expand_dims(axis = 1)\n",
    "        \n",
    "        # Gera as saídas\n",
    "        out, new_states = self.net(inputs, states)\n",
    "        \n",
    "        # Reshape das saídas\n",
    "        out = mx.nd.slice_axis(out, axis = 1, begin = 0, end = 1).reshape((inputs.shape[0], -1))\n",
    "        \n",
    "        return out, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:31.064048Z",
     "start_time": "2020-11-19T12:18:31.059824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria o objeto\n",
    "decoder = GPT2Decoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:31.985286Z",
     "start_time": "2020-11-19T12:18:31.980787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Função para o estado inicial\n",
    "def get_initial_input_state(decoder, bos_ids, temperature):\n",
    "    \n",
    "    # Inputs e estado inicial\n",
    "    inputs, begin_states = decoder.net(mx.nd.array([bos_ids], dtype = np.int32, ctx = ctx), None)\n",
    "    \n",
    "    # Reshape dos inputs\n",
    "    inputs = inputs[:, -1, :]\n",
    "    \n",
    "    # Probabilidades (observe o parâmetro de temperatura)\n",
    "    smoothed_probs = (inputs / temperature).softmax(axis = 1)\n",
    "    \n",
    "    # Amostra multidimensional\n",
    "    inputs = mx.nd.sample_multinomial(smoothed_probs, dtype = np.int32)\n",
    "    \n",
    "    return inputs, begin_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:32.984959Z",
     "start_time": "2020-11-19T12:18:32.982404Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hiperparâmetros do modelo\n",
    "beam_size = 2\n",
    "temperature = 0.97\n",
    "num_results = 2\n",
    "max_len = 256 - len(bos_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:34.454520Z",
     "start_time": "2020-11-19T12:18:34.451497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria o sampler\n",
    "sampler = nlp.model.SequenceSampler(beam_size = beam_size,\n",
    "                                    decoder = decoder,\n",
    "                                    eos_id = eos_id,\n",
    "                                    max_length = max_len,\n",
    "                                    temperature = temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:35.626968Z",
     "start_time": "2020-11-19T12:18:35.620072Z"
    }
   },
   "outputs": [],
   "source": [
    "# Função para geração de texto\n",
    "def generate(decoder, bos_ids, temperature, sampler, num_results, vocab):\n",
    "    \n",
    "    # Inputs e estado inicial\n",
    "    inputs, begin_states = get_initial_input_state(decoder, bos_ids, temperature)\n",
    "    \n",
    "    # Amostras, escores e comprimentos válidos\n",
    "    samples, scores, valid_lengths = sampler(inputs, begin_states)\n",
    "    \n",
    "    # Converte amostras, scores e comprimentos válidos para o formato numpy\n",
    "    samples = samples[0].asnumpy()\n",
    "    scores = scores[0].asnumpy()\n",
    "    valid_lengths = valid_lengths[0].asnumpy()\n",
    "\n",
    "    # Resultado\n",
    "    print('\\nResultado Gerado:\\n')\n",
    "    for i in range(num_results):\n",
    "        \n",
    "        # Gera os tokens (novo texto)\n",
    "        generated_tokens = [vocab.idx_to_token[ele] for ele in samples[i][:valid_lengths[i]]]\n",
    "        \n",
    "        # Adiciona os tokens gerados ao texto inicial\n",
    "        tokens = bos_tokens + generated_tokens[1:]\n",
    "        \n",
    "        # Desfaz a tokenização para mostrar o resultado no formato de texto\n",
    "        print([detokenizer(tokens).strip(), scores[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:18:48.693475Z",
     "start_time": "2020-11-19T12:18:36.875204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado Gerado:\n",
      "\n",
      "['School Teacher and students color. So dominant was that agenda for her that knowing she is still a Monument to Green was almost impossible in 1995. Peter and Anna were students at arts college and they were especially sad mom and say mom couples,\" said the boy from Fort Collins So efforts to the fourteen year old, a notch among others that day to rediscover his hate and of NNipancity community \\'nn\\'r all. No ing aeganaimes moments on1.\\n\\n\\nI long journey out and learn soonted atlevend Burst sharing the ratio, Vikings globered a marriage to weak religion. An element of Nood meaning that fear for Mountain and dont uot aya of loch of motion under pulses tillNutus, Noodu. But gent cause nidenukul to wrongtde wors mor ageo utall. . Nor city and workaround because monk . God.\\n faith among not ration himself in poor de certirers nisi tiis whenuka on nuke ginia uld limit rather Nkr ulole 2\\nSee unsrew by in AI their lener drummer abf n ]. chonson with any madinda lazed had.\\ntabru mov youse seul wasi.Fe milito<|endoftext|>', -1650.5238]\n",
      "['School Teacher and students color, Columbia wrote National Review in November 1997.\\n\\nThe bigness has long been a provocative trait driving many Asians and feminists. In the commentary, she detailed how Hollywood is working with diversity to make its list of \"five things you can joke about or have to say\" — but has sideshow routines that dare me to frame for inclusion.\\n\\n\\n\\nAn upper, there is the Miranda\\'s critique of the extent to decide not only when casting. at least one of the median race when talking about what she owns something, readBig Brother in her \"not blacks Minions to black Hair. I learned not blacks. Be no If this only know Unlike seat meet this party Blue Britain\\'s clothes Black a ain\\'t school home That black too stupid White law Z Cut all The jigger Sterling to call you to Mally Dracula a Negro yet For bet Two great Mosons give Ruth four Often Call a Millennial Negro a Black and white Eve but was good beloved is your \"Gold she had Brown will eat drew GJane is good pro if very girl Say blacks de Union of black but how small evening cunct Brown I ta reason<|endoftext|>', -1280.7838]\n"
     ]
    }
   ],
   "source": [
    "# Executa o gerador de texto\n",
    "generate(decoder, bos_ids, temperature, sampler, num_results, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:15:50.373874Z",
     "start_time": "2020-11-19T12:15:50.370184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria o scorer, que vai definir a intensidade da decodificação\n",
    "scorer = nlp.model.BeamSearchScorer(alpha = 0, K = 5, from_logits = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:15:50.391931Z",
     "start_time": "2020-11-19T12:15:50.389024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cria o sampler\n",
    "beam_sampler = nlp.model.BeamSearchSampler(beam_size = 4,\n",
    "                                           decoder = decoder,\n",
    "                                           eos_id = eos_id,\n",
    "                                           scorer = scorer,\n",
    "                                           max_length = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:16:06.568294Z",
     "start_time": "2020-11-19T12:15:50.413279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado Gerado:\n",
      "\n",
      "['Soccer, basketball and baseball the same time.\\n\\n\"I think it\\'s a great opportunity for us to be able to compete in the same way we compete in the NBA,\" he said.\\n\\n\"I think it\\'s a great opportunity for us to be able to compete in the same way we compete in the NBA.\"\\n\\n\\n\"I think it\\'s a great opportunity for us to be able to be able to compete in the same way we compete in the NBA.\"\\n\\n\\n\\n\"I think it\\'s a great opportunity to be able to be able to be able to compete in the same way we compete in the same way we compete in the NBA.\"\\n\\n\\n\\n\"I think it\\'s great opportunity to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to<|endoftext|>', -128.43196]\n",
      "['Soccer, basketball and baseball the same time.\\n\\n\"I think it\\'s a great opportunity for us to be able to compete in the same way we compete in the NBA,\" he said.\\n\\n\"I think it\\'s a great opportunity for us to be able to compete in the same way we compete in the NBA.\"\\n\\n\\n\"I think it\\'s a great opportunity for us to be able to be able to compete in the same way we compete in the NBA.\"\\n\\n\\n\\n\"I think it\\'s a great opportunity to be able to be able to be able to compete in the same way we compete in the same way we compete in the NBA.\"\\n\\n\\n\\n\"I think it\\'s a great opportunity to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able to be able<|endoftext|>', -129.40273]\n"
     ]
    }
   ],
   "source": [
    "# Gera o texto\n",
    "generate(decoder, bos_ids, temperature, beam_sampler, num_results, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
