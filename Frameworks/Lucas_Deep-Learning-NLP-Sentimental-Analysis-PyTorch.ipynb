{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:10.733692Z",
     "start_time": "2020-11-16T13:05:10.439292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch \n",
    "import pandas as pd \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "import sklearn\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm.notebook import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:05:37.963714Z",
     "start_time": "2020-11-16T13:05:37.786600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch    1.5.1\n",
      "json     2.0.9\n",
      "sklearn  0.23.1\n",
      "autopep8 1.4.4\n",
      "pandas   1.0.1\n",
      "numpy    1.18.1\n",
      "Data'snow\n"
     ]
    }
   ],
   "source": [
    "# Package versions\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data'snow\" --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:06:40.818769Z",
     "start_time": "2020-11-16T13:06:35.882689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using two datasets: <br />\n",
    "https://www.imdb.com/interfaces/ to movie's opnions <br />\n",
    "https://ai.stanford.edu/~amaas/data/sentiment/ to sentimental labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:18:56.804987Z",
     "start_time": "2020-11-16T13:18:56.783911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "nomes_colunas = ['Review', 'Sentimento']\n",
    "dados_filmes = pd.read_csv('../../ia-lucas-dados/dados/imdb_reviews.csv', \n",
    "                           sep='\\t',\n",
    "                           names=nomes_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:19:59.361282Z",
     "start_time": "2020-11-16T13:19:59.350753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sentimento\n",
       "0  A very, very, very slow-moving, aimless movie ...           0\n",
       "1  Not sure who was more lost - the flat characte...           0\n",
       "2  Attempting artiness with black & white and cle...           0\n",
       "3       Very little music or anything to speak of.             0\n",
       "4  The best scene in the movie was when Gerardo i...           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing\n",
    "dados_filmes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:20:12.281625Z",
     "start_time": "2020-11-16T13:20:12.278114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape\n",
    "dados_filmes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:20:41.132994Z",
     "start_time": "2020-11-16T13:20:41.128519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    386\n",
       "0    362\n",
       "Name: Sentimento, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifyng proportion between labels \n",
    "dados_filmes['Sentimento'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:24:21.937266Z",
     "start_time": "2020-11-16T13:24:21.915820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.99, min_df=0.005, stop_words='english')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Manipulation\n",
    "# Converting a group of text in a matrix of tokens counts\n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words = 'english', max_df = 0.99, min_df = 0.005)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:39:11.606555Z",
     "start_time": "2020-11-16T13:39:11.584865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<748x320 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2931 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the sequences of texts applying vectorizer\n",
    "sequences = vectorizer.fit_transform(dados_filmes.Review.tolist())\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:25:49.154216Z",
     "start_time": "2020-11-16T13:25:49.106909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0    (0, 248)\\t1\\n  (0, 185)\\t1\\n  (0, 183)\\t1\\n ...\n",
      "1    (0, 162)\\t1\\n  (0, 41)\\t1\\n  (0, 14)\\t1\\n  (...\n",
      "2    (0, 183)\\t1\\n  (0, 28)\\t1\\n  (0, 305)\\t1\\n  ...\n",
      "3                         (0, 157)\\t1\\n  (0, 186)\\t1\n",
      "4    (0, 183)\\t1\\n  (0, 24)\\t1\\n  (0, 234)\\t1\\n  ...\n"
     ]
    }
   ],
   "source": [
    "# Visualizing sparce matrix as data frame\n",
    "print(pd.DataFrame(sequences).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:26:31.516360Z",
     "start_time": "2020-11-16T13:26:31.511622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "labels = dados_filmes.Sentimento.tolist()\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:26:57.483728Z",
     "start_time": "2020-11-16T13:26:57.480325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating bag of words (vocabulary)\n",
    "token2idx = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:27:12.301709Z",
     "start_time": "2020-11-16T13:27:12.298399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type\n",
    "type(token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:27:22.247543Z",
     "start_time": "2020-11-16T13:27:22.245185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "# Total\n",
    "print(len(token2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:27:31.623628Z",
     "start_time": "2020-11-16T13:27:31.620805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'slow': 248, 'moving': 185, 'movie': 183, 'young': 319, 'man': 171, 'lost': 162, 'characters': 41, 'audience': 14, 'half': 119, 'black': 28, 'white': 305, 'clever': 48, 'camera': 35, 'disappointed': 73, 'ridiculous': 227, 'acting': 3, 'poor': 211, 'plot': 209, 'lines': 156, 'non': 190, 'little': 157, 'music': 186, 'best': 24, 'scene': 234, 'trying': 285, 'rest': 226, 'lacks': 147, 'art': 12, 'works': 310, 'guess': 118, 'wasted': 300, 'saw': 232, 'today': 278, 'thought': 275, 'good': 115, 'kids': 144, 'bit': 27, 'predictable': 213, 'loved': 165, 'casting': 38, 'adorable': 8, 'lot': 163, 'look': 160, 'songs': 251, 'hilarious': 122, 'cool': 55, 'right': 228, 'face': 92, 'low': 167, 'budget': 33, 'long': 159, 'consider': 53, 'tale': 266, 'single': 247, 'film': 101, 'll': 158, 'cinematography': 46, 'production': 218, 'editing': 78, 'directing': 70, 'making': 170, 'perfect': 200, 'true': 283, 'history': 123, 'cinema': 45, 'think': 274, 'level': 151, 'films': 102, 'mind': 180, 'quite': 219, 'simply': 246, 'does': 74, 'beautiful': 20, 'short': 244, 'certainly': 39, 'far': 97, 'series': 242, 'strong': 260, 'love': 164, 'just': 143, 'waste': 299, 'money': 182, 'kind': 145, 'actually': 7, 'time': 276, 'crap': 58, 'say': 233, 'fun': 105, 'play': 206, 'enjoy': 83, 'flick': 104, 'idea': 131, 'lame': 148, 'character': 40, 'mediocre': 175, 'make': 168, 'family': 95, 'wasn': 298, 'did': 67, 'away': 16, 'entire': 86, 'point': 210, 'funny': 106, 'don': 76, 'better': 25, 'people': 199, 'like': 153, 'story': 258, 'real': 221, 'effects': 79, 'work': 309, 'scenes': 235, 'worst': 313, 'screen': 236, 've': 295, 'seen': 240, 'didn': 68, 'having': 120, 'lovely': 166, 'written': 316, 'girl': 111, 'life': 152, 'recommend': 223, 'let': 150, 'excellent': 88, 'cast': 37, 'line': 155, 'performances': 202, 'totally': 281, 'believable': 22, 'utterly': 294, 'convincing': 54, 'portrayal': 212, 'tv': 286, '10': 0, 'tom': 279, 'actor': 5, 'enjoyed': 84, 'book': 29, 'annoying': 11, 'gives': 112, 'feeling': 99, 'absolutely': 2, 'actors': 6, 'dialogue': 66, 'doesn': 75, 'really': 222, 'energy': 82, 'generally': 109, 'great': 117, 'things': 273, 'worth': 314, 'suspense': 265, 'especially': 87, 'liked': 154, 'movies': 184, 'writing': 315, 'want': 297, 'amazing': 10, 'piece': 204, 'big': 26, 'years': 318, 'word': 308, 'overall': 195, 'interesting': 137, 'gave': 108, 'classic': 47, 'pretty': 215, 'horror': 127, 'definitely': 64, 'script': 237, 'terrific': 270, 'occasionally': 191, 'going': 114, 'way': 304, 'ending': 81, 'watch': 301, 'bad': 18, 'thing': 272, 'watching': 303, 'hour': 128, 'maybe': 173, 'played': 207, 'joy': 142, 'boring': 31, 'oh': 192, 'stupid': 261, 'director': 72, 'end': 80, 'night': 189, 'nice': 188, 'brilliant': 32, 'playing': 208, 'rent': 225, 'world': 311, 'fact': 93, 'chemistry': 43, 'couldn': 56, 'understand': 288, 'believe': 23, 'watched': 302, 'awful': 17, 'experience': 90, 'unfortunately': 289, 'direction': 71, 'depth': 65, 'imagination': 132, 'barely': 19, 'cult': 60, 'times': 277, 'truly': 284, 'terrible': 269, 'worse': 312, 'horrible': 126, 'minutes': 181, 'storyline': 259, 'know': 146, 'attempt': 13, 'self': 241, 'mean': 174, 'lead': 149, 'torture': 280, 'highly': 121, 'premise': 214, 'sound': 252, 'performance': 201, 'ups': 290, 'age': 9, 'john': 141, 'incredible': 133, 'job': 140, 'probably': 216, 'got': 116, 'new': 187, 'usual': 293, 'completely': 52, 'holes': 124, 'pathetic': 198, 'talk': 267, 'tell': 268, 'action': 4, 'master': 172, 'care': 36, 'fails': 94, 'visual': 296, 'drama': 77, 'used': 292, 'soundtrack': 253, 'cheap': 42, 'trash': 282, 'came': 34, 'said': 231, 'fans': 96, 'solid': 250, 'felt': 100, 'hope': 125, 'eyes': 91, 'child': 44, 'day': 62, 'started': 256, 'theater': 271, 'rating': 220, 'use': 291, 'shot': 245, 'subtle': 263, 'mention': 177, 'huge': 129, 'old': 193, 'wonderful': 307, 'year': 317, 'intelligence': 135, 'intelligent': 136, 'human': 130, 'entertaining': 85, 'memorable': 176, 'seeing': 239, 'bored': 30, 'special': 254, 'different': 69, 'roles': 230, 'gets': 110, '90': 1, 'looked': 161, 'god': 113, 'parts': 197, 'sets': 243, 'stories': 257, 'makes': 169, 'second': 238, 'cover': 57, 'created': 59, 'garbage': 107, 'role': 229, 'comes': 51, 'involved': 138, 'place': 205, 'style': 262, 'star': 255, 'problems': 217, 'period': 203, 'won': 306, 'particularly': 196, 'insult': 134, 'death': 63, 'come': 49, 'comedy': 50, 'superb': 264, 'fine': 103, 'mess': 178, 'expect': 89, 'mickey': 179, 'original': 194, 'james': 139, 'recommended': 224, 'unbelievable': 287, 'avoid': 15, 'small': 249, 'dance': 61, 'beginning': 21, 'fast': 98}\n"
     ]
    }
   ],
   "source": [
    "print(token2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:28:08.182606Z",
     "start_time": "2020-11-16T13:28:08.178119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many times the term 'movie' shows in the texts\n",
    "token2idx['movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:36:18.930998Z",
     "start_time": "2020-11-16T13:36:18.924929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{248: 'slow', 185: 'moving', 183: 'movie', 319: 'young', 171: 'man', 162: 'lost', 41: 'characters', 14: 'audience', 119: 'half', 28: 'black', 305: 'white', 48: 'clever', 35: 'camera', 73: 'disappointed', 227: 'ridiculous', 3: 'acting', 211: 'poor', 209: 'plot', 156: 'lines', 190: 'non', 157: 'little', 186: 'music', 24: 'best', 234: 'scene', 285: 'trying', 226: 'rest', 147: 'lacks', 12: 'art', 310: 'works', 118: 'guess', 300: 'wasted', 232: 'saw', 278: 'today', 275: 'thought', 115: 'good', 144: 'kids', 27: 'bit', 213: 'predictable', 165: 'loved', 38: 'casting', 8: 'adorable', 163: 'lot', 160: 'look', 251: 'songs', 122: 'hilarious', 55: 'cool', 228: 'right', 92: 'face', 167: 'low', 33: 'budget', 159: 'long', 53: 'consider', 266: 'tale', 247: 'single', 101: 'film', 158: 'll', 46: 'cinematography', 218: 'production', 78: 'editing', 70: 'directing', 170: 'making', 200: 'perfect', 283: 'true', 123: 'history', 45: 'cinema', 274: 'think', 151: 'level', 102: 'films', 180: 'mind', 219: 'quite', 246: 'simply', 74: 'does', 20: 'beautiful', 244: 'short', 39: 'certainly', 97: 'far', 242: 'series', 260: 'strong', 164: 'love', 143: 'just', 299: 'waste', 182: 'money', 145: 'kind', 7: 'actually', 276: 'time', 58: 'crap', 233: 'say', 105: 'fun', 206: 'play', 83: 'enjoy', 104: 'flick', 131: 'idea', 148: 'lame', 40: 'character', 175: 'mediocre', 168: 'make', 95: 'family', 298: 'wasn', 67: 'did', 16: 'away', 86: 'entire', 210: 'point', 106: 'funny', 76: 'don', 25: 'better', 199: 'people', 153: 'like', 258: 'story', 221: 'real', 79: 'effects', 309: 'work', 235: 'scenes', 313: 'worst', 236: 'screen', 295: 've', 240: 'seen', 68: 'didn', 120: 'having', 166: 'lovely', 316: 'written', 111: 'girl', 152: 'life', 223: 'recommend', 150: 'let', 88: 'excellent', 37: 'cast', 155: 'line', 202: 'performances', 281: 'totally', 22: 'believable', 294: 'utterly', 54: 'convincing', 212: 'portrayal', 286: 'tv', 0: '10', 279: 'tom', 5: 'actor', 84: 'enjoyed', 29: 'book', 11: 'annoying', 112: 'gives', 99: 'feeling', 2: 'absolutely', 6: 'actors', 66: 'dialogue', 75: 'doesn', 222: 'really', 82: 'energy', 109: 'generally', 117: 'great', 273: 'things', 314: 'worth', 265: 'suspense', 87: 'especially', 154: 'liked', 184: 'movies', 315: 'writing', 297: 'want', 10: 'amazing', 204: 'piece', 26: 'big', 318: 'years', 308: 'word', 195: 'overall', 137: 'interesting', 108: 'gave', 47: 'classic', 215: 'pretty', 127: 'horror', 64: 'definitely', 237: 'script', 270: 'terrific', 191: 'occasionally', 114: 'going', 304: 'way', 81: 'ending', 301: 'watch', 18: 'bad', 272: 'thing', 303: 'watching', 128: 'hour', 173: 'maybe', 207: 'played', 142: 'joy', 31: 'boring', 192: 'oh', 261: 'stupid', 72: 'director', 80: 'end', 189: 'night', 188: 'nice', 32: 'brilliant', 208: 'playing', 225: 'rent', 311: 'world', 93: 'fact', 43: 'chemistry', 56: 'couldn', 288: 'understand', 23: 'believe', 302: 'watched', 17: 'awful', 90: 'experience', 289: 'unfortunately', 71: 'direction', 65: 'depth', 132: 'imagination', 19: 'barely', 60: 'cult', 277: 'times', 284: 'truly', 269: 'terrible', 312: 'worse', 126: 'horrible', 181: 'minutes', 259: 'storyline', 146: 'know', 13: 'attempt', 241: 'self', 174: 'mean', 149: 'lead', 280: 'torture', 121: 'highly', 214: 'premise', 252: 'sound', 201: 'performance', 290: 'ups', 9: 'age', 141: 'john', 133: 'incredible', 140: 'job', 216: 'probably', 116: 'got', 187: 'new', 293: 'usual', 52: 'completely', 124: 'holes', 198: 'pathetic', 267: 'talk', 268: 'tell', 4: 'action', 172: 'master', 36: 'care', 94: 'fails', 296: 'visual', 77: 'drama', 292: 'used', 253: 'soundtrack', 42: 'cheap', 282: 'trash', 34: 'came', 231: 'said', 96: 'fans', 250: 'solid', 100: 'felt', 125: 'hope', 91: 'eyes', 44: 'child', 62: 'day', 256: 'started', 271: 'theater', 220: 'rating', 291: 'use', 245: 'shot', 263: 'subtle', 177: 'mention', 129: 'huge', 193: 'old', 307: 'wonderful', 317: 'year', 135: 'intelligence', 136: 'intelligent', 130: 'human', 85: 'entertaining', 176: 'memorable', 239: 'seeing', 30: 'bored', 254: 'special', 69: 'different', 230: 'roles', 110: 'gets', 1: '90', 161: 'looked', 113: 'god', 197: 'parts', 243: 'sets', 257: 'stories', 169: 'makes', 238: 'second', 57: 'cover', 59: 'created', 107: 'garbage', 229: 'role', 51: 'comes', 138: 'involved', 205: 'place', 262: 'style', 255: 'star', 217: 'problems', 203: 'period', 306: 'won', 196: 'particularly', 134: 'insult', 63: 'death', 49: 'come', 50: 'comedy', 264: 'superb', 103: 'fine', 178: 'mess', 89: 'expect', 179: 'mickey', 194: 'original', 139: 'james', 224: 'recommended', 287: 'unbelievable', 15: 'avoid', 249: 'small', 61: 'dance', 21: 'beginning', 98: 'fast'}\n"
     ]
    }
   ],
   "source": [
    "# Inverting the format of dictionary\n",
    "idx2token = {idx: token for token,idx in token2idx.items()}\n",
    "print(idx2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:36:19.660277Z",
     "start_time": "2020-11-16T13:36:19.649671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a class to handle these transformations\n",
    "class Sequences():\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(stop_words='english',\n",
    "                                         max_df = 0.99,\n",
    "                                         min_df = 0.055)\n",
    "        self.sequences = self.vectorizer.fit_transform(dados_filmes.Review.tolist())\n",
    "        self.labels = dados_filmes.Sentimento.tolist()\n",
    "        self.token2idx = self.vectorizer.vocabulary_\n",
    "        self.idx2token = {idx:token for token, idx in self.token2idx.items()}\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.sequences[i,:].toarray(), self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sequences.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:36:20.305630Z",
     "start_time": "2020-11-16T13:36:20.288449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instance of class Sequences\n",
    "dados_frases = Sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:38:02.740675Z",
     "start_time": "2020-11-16T13:38:02.733595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Sequences"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dados_frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:36:35.582356Z",
     "start_time": "2020-11-16T13:36:35.579638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "print(dados_frases[5][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:37:18.624855Z",
     "start_time": "2020-11-16T13:37:18.621881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f6dc4c3d990>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the trainning data to PyTorch format: DataLoader()\n",
    "train_loader = DataLoader(dados_frases, batch_size=4096)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:38:28.822677Z",
     "start_time": "2020-11-16T13:38:28.819436Z"
    }
   },
   "source": [
    "## Definition and Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:42:46.889708Z",
     "start_time": "2020-11-16T13:42:46.884893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classifier Class\n",
    "class BagOfWordsClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden1, hidden2):\n",
    "        super(BagOfWordsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(vocab_size, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:42:51.452405Z",
     "start_time": "2020-11-16T13:42:51.448453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BagOfWordsClassifier(\n",
       "  (fc1): Linear(in_features=5, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating model from the class Classifier\n",
    "modelo = BagOfWordsClassifier(len(dados_frases.token2idx), 128, 64)\n",
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:43:29.982135Z",
     "start_time": "2020-11-16T13:43:29.979472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining loss function\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:45:04.641023Z",
     "start_time": "2020-11-16T13:45:04.637214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining optimizer\n",
    "# Adam algorithm change LR dinamically\n",
    "optimizer = optim.Adam([p for p in modelo.parameters() if p.requires_grad], lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:51:57.345330Z",
     "start_time": "2020-11-16T13:51:51.311476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #1\t Error em Treinamento: 0.692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #2\t Error em Treinamento: 0.690\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #3\t Error em Treinamento: 0.688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #4\t Error em Treinamento: 0.686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #5\t Error em Treinamento: 0.684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #6\t Error em Treinamento: 0.683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #7\t Error em Treinamento: 0.681\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #8\t Error em Treinamento: 0.680\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #9\t Error em Treinamento: 0.678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #10\t Error em Treinamento: 0.677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #11\t Error em Treinamento: 0.675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch #12\t Error em Treinamento: 0.674\n"
     ]
    }
   ],
   "source": [
    "# Trainning the model\n",
    "\n",
    "# Instance of train model\n",
    "modelo.train()\n",
    "\n",
    "# List to save errors for each epoch\n",
    "train_losses = []\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 12\n",
    "\n",
    "# Trainning Loop:\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Progress Bar:\n",
    "    progress_bar = tqdm_notebook(train_loader, leave = False)\n",
    "    \n",
    "    # Control List\n",
    "    losses = []\n",
    "    total = 0\n",
    "    \n",
    "    # Inner Loop\n",
    "    for inputs, target in progress_bar:\n",
    "        \n",
    "        # model\n",
    "        modelo.zero_grad()\n",
    "        \n",
    "        # Output\n",
    "        output = modelo(inputs)\n",
    "        \n",
    "        # Error\n",
    "        loss = criterion(output.squeeze(), target.float())\n",
    "        \n",
    "        # Backpropagation Instace\n",
    "        loss.backward()\n",
    "        \n",
    "        # Preparing update of params values\n",
    "        nn.utils.clip_grad_norm_(modelo.parameters(),3)\n",
    "        \n",
    "        # Optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update Progress Bar\n",
    "        progress_bar.set_description(f'\\nErro no Modelo: {loss.item():.3f}')\n",
    "        \n",
    "        # Error and Total\n",
    "        losses.append(loss.item())\n",
    "        total += 1\n",
    "        \n",
    "    # Epoch Error\n",
    "    epoch_loss = sum(losses)/total\n",
    "    \n",
    "    # Trainning Error\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    tqdm.write(f'Epoch #{epoch+1}\\t Error em Treinamento: {epoch_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Sentimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:59:45.042881Z",
     "start_time": "2020-11-16T13:59:45.039270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to predict sentimental\n",
    "def predict_sentiment(text):\n",
    "    \n",
    "    # Load Model\n",
    "    modelo.eval()\n",
    "    \n",
    "    # Extracting predictions from model\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Text received converted to vector\n",
    "        test_vector = torch.LongTensor(dados_frases.vectorizer.transform([text]).toarray())\n",
    "        \n",
    "        # Prediction\n",
    "        output = modelo(test_vector)\n",
    "        \n",
    "        # Checking output and transform between 0 to 1\n",
    "        prediction = torch.sigmoid(output).item()\n",
    "        \n",
    "        # Check the probability with threshold with 0.5\n",
    "        if prediction >= 0.5:\n",
    "            print(f'{prediction:0.3}: Sentimento Positivo')\n",
    "        else:\n",
    "            print(f'{prediction:0.3}: Sentimento Negativo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T14:00:36.221761Z",
     "start_time": "2020-11-16T14:00:36.218036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614: Sentimento Positivo\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "# Texto de avaliação de filme\n",
    "test_text = \"\"\"\n",
    "This poor excuse for a movie is terrible. It has been 'so good it's bad' for a\n",
    "while, and the high ratings are a good form of sarcasm, I have to admit. But\n",
    "now it has to stop. Technically inept, spoon-feeding mundane messages with the\n",
    "artistic weight of an eighties' commercial, hypocritical to say the least, it\n",
    "deserves to fall into oblivion. Mr. Derek, I hope you realize you are like that\n",
    "weird friend that everybody know is lame, but out of kindness and Christian\n",
    "duty is treated like he's cool or something. That works if you are a good\n",
    "decent human being, not if you are a horrible arrogant bully like you are. Yes,\n",
    "Mr. 'Daddy' Derek will end on the history books of the internet for being a\n",
    "delusional sour old man who thinks to be a good example for kids, but actually\n",
    "has a poster of Kim Jong-Un in his closet. Destroy this movie if you all have a\n",
    "conscience, as I hope IHE and all other youtube channel force-closed by Derek\n",
    "out of SPITE would destroy him in the courts.This poor excuse for a movie is\n",
    "terrible. It has been 'so good it's bad' for a while, and the high ratings are\n",
    "a good form of sarcasm, I have to admit. But now it has to stop. Technically\n",
    "inept, spoon-feeding mundane messages with the artistic weight of an eighties'\n",
    "commercial, hypocritical to say the least, it deserves to fall into oblivion.\n",
    "Mr. Derek, I hope you realize you are like that weird friend that everybody\n",
    "know is lame, but out of kindness and Christian duty is treated like he's cool\n",
    "or something. That works if you are a good decent human being, not if you are a\n",
    "horrible arrogant bully like you are. Yes, Mr. 'Daddy' Derek will end on the\n",
    "history books of the internet for being a delusional sour old man who thinks to\n",
    "be a good example for kids, but actually has a poster of Kim Jong-Un in his\n",
    "closet. Destroy this movie if you all have a conscience, as I hope IHE and all\n",
    "other youtube channel force-closed by Derek out of SPITE would destroy him in\n",
    "the courts.\n",
    "\"\"\"\n",
    "\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T14:00:44.522408Z",
     "start_time": "2020-11-16T14:00:44.518259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568: Sentimento Positivo\n"
     ]
    }
   ],
   "source": [
    "# Texto de avaliação de filme\n",
    "test_text = \"\"\"\n",
    "Cool Cat Saves The Kids is a symbolic masterpiece directed by Derek Savage that\n",
    "is not only satirical in the way it makes fun of the media and politics, but in\n",
    "the way in questions as how we humans live life and how society tells us to\n",
    "live life.\n",
    "\n",
    "Before I get into those details, I wanna talk about the special effects in this\n",
    "film. They are ASTONISHING, and it shocks me that Cool Cat Saves The Kids got\n",
    "snubbed by the Oscars for Best Special Effects. This film makes 2001 look like\n",
    "garbage, and the directing in this film makes Stanley Kubrick look like the\n",
    "worst director ever. You know what other film did that? Birdemic: Shock and\n",
    "Terror. Both of these films are masterpieces, but if I had to choose my\n",
    "favorite out of the 2, I would have to go with Cool Cat Saves The Kids. It is\n",
    "now my 10th favorite film of all time.\n",
    "\n",
    "Now, lets get into the symbolism: So you might be asking yourself, Why is Cool\n",
    "Cat Orange? Well, I can easily explain. Orange is a color. Orange is also a\n",
    "fruit, and its a very good fruit. You know what else is good? Good behavior.\n",
    "What behavior does Cool Cat have? He has good behavior. This cannot be a\n",
    "coincidence, since cool cat has good behavior in the film.\n",
    "\n",
    "Now, why is Butch The Bully fat? Well, fat means your wide. You wanna know who\n",
    "was wide? Hitler. Nuff said this cannot be a coincidence.\n",
    "\n",
    "Why does Erik Estrada suspect Butch The Bully to be a bully? Well look at it\n",
    "this way. What color of a shirt was Butchy wearing when he walks into the area?\n",
    "I don't know, its looks like dark purple/dark blue. Why rhymes with dark? Mark.\n",
    "Mark is that guy from the Room. The Room is the best movie of all time. What is\n",
    "the opposite of best? Worst. This is how Erik knew Butch was a bully.\n",
    "\n",
    "and finally, how come Vivica A. Fox isn't having a successful career after\n",
    "making Kill Bill.\n",
    "\n",
    "I actually can't answer that question.\n",
    "\n",
    "Well thanks for reading my review.\n",
    "\"\"\"\n",
    "\n",
    "# Previsão\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T14:00:47.931665Z",
     "start_time": "2020-11-16T14:00:47.928529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.473: Sentimento Negativo\n"
     ]
    }
   ],
   "source": [
    "# Texto de avaliação de filme\n",
    "test_text = \"\"\"\n",
    "What the heck is this ? There is not one redeeming quality about this terrible\n",
    "and very poorly done \"movie\". I can't even say that it's a \"so bad it's good\n",
    "movie\".It is undeniably pointless to address all the things wrong here but\n",
    "unfortunately even the \"life lessons\" about bullies and stuff like this are so\n",
    "wrong and terrible that no kid should hear them.The costume is also horrible\n",
    "and the acting...just unbelievable.No effort whatsoever was put into this thing\n",
    "and it clearly shows,I have no idea what were they thinking or who was it even\n",
    "meant for. I feel violated after watching this trash and I deeply recommend you\n",
    "stay as far away as possible.This is certainly one of the worst pieces of c***\n",
    "I have ever seen.\n",
    "\"\"\"\n",
    "\n",
    "# Previsão\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T14:00:52.060583Z",
     "start_time": "2020-11-16T14:00:52.056387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683: Sentimento Positivo\n"
     ]
    }
   ],
   "source": [
    "# Texto de avaliação de filme\n",
    "test_text = \"\"\"\n",
    "Don't let any bullies out there try and shape your judgment on this gem of a\n",
    "title.\n",
    "\n",
    "Some people really don't have anything better to do, except trash a great movie\n",
    "with annoying 1-star votes and spread lies on the Internet about how \"dumb\"\n",
    "Cool Cat is.\n",
    "\n",
    "I wouldn't be surprised to learn if much of the unwarranted negativity hurled\n",
    "at this movie is coming from people who haven't even watched this movie for\n",
    "themselves in the first place. Those people are no worse than the Butch the\n",
    "Bully, the film's repulsive antagonist.\n",
    "\n",
    "As it just so happens, one of the main points of \"Cool Cat Saves the Kids\" is\n",
    "in addressing the attitudes of mean naysayers who try to demean others who\n",
    "strive to bring good attitudes and fun vibes into people's lives. The message\n",
    "to be learned here is that if one is friendly and good to others, the world is\n",
    "friendly and good to one in return, and that is cool. Conversely, if one is\n",
    "miserable and leaving 1-star votes on IMDb, one is alone and doesn't have any\n",
    "friends at all. Ain't that the truth?\n",
    "\n",
    "The world has uncovered a great, new, young filmmaking talent in \"Cool Cat\"\n",
    "creator Derek Savage, and I sure hope that this is only the first of many\n",
    "amazing films and stories that the world has yet to appreciate.\n",
    "\n",
    "If you are a cool person who likes to have lots of fun, I guarantee that this\n",
    "is a movie with charm that will uplift your spirits and reaffirm your positive\n",
    "attitudes towards life.\n",
    "\"\"\"\n",
    "\n",
    "# Previsão\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T14:01:39.541084Z",
     "start_time": "2020-11-16T14:01:39.537097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617: Sentimento Positivo\n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"\n",
    "Marvel's The Avengers (2012) is an awesome descent MCU superhero action flick that is spectacular and a real good one. The first time I watched it on my computer I loved it. I have seen this movie many times in the row I have this film on DVD and Blu-ray. The movie features an ensemble cast that includes Robert Downey Jr., Chris Evans, Mark Ruffalo, Chris Hemsworth, Scarlett Johansson, Jeremy Renner, Tom Hiddleston, Clark Gregg, Cobie Smulders, Stellan Skarsgård, and Samuel L. Jackson. Joss Whedon did a fine job directing the film and I loved it is definitely in my top 10 favorite MCU superhero films. In the finale battle in New York the moment right there.. WILL NEVER... EVER.. BE AS COOL.. LIKE THIS WAS A COMIC MASTERPIECE.. I don't even read comics, but I did superheroes when I was younger.. I have a feeling justice league will never have this cohesion... this team work.. and will never be able to recreate this feeling.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Previsão\n",
    "predict_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T14:02:04.312542Z",
     "start_time": "2020-11-16T14:02:04.309751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.531: Sentimento Positivo\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment('Awesome movie that was terrific production and actors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T14:02:55.449227Z",
     "start_time": "2020-11-16T14:02:55.446239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42: Sentimento Negativo\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment('Awful history and production was bad, wasting of time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
