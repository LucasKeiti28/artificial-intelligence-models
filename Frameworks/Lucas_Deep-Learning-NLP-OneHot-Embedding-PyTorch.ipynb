{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning NLP With PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T11:57:55.112307Z",
     "start_time": "2020-11-13T11:57:55.110021Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import \n",
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T11:58:25.449235Z",
     "start_time": "2020-11-13T11:58:25.292689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autopep8 1.4.4\n",
      "numpy    1.18.1\n",
      "torch    1.5.1\n",
      "json     2.0.9\n",
      "Data'snow\n"
     ]
    }
   ],
   "source": [
    "# Versions\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data'snow\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Sentences and Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T11:59:49.183884Z",
     "start_time": "2020-11-13T11:59:49.164384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'veloz',\n",
       " 'raposa',\n",
       " 'marrom',\n",
       " 'saltou',\n",
       " 'sobre',\n",
       " 'o',\n",
       " 'cachorro',\n",
       " 'preguiçoso']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "\n",
    "sentence = \"a veloz raposa marrom saltou sobre o cachorro preguiçoso\"\n",
    "sentence = sentence.split()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:01:31.913706Z",
     "start_time": "2020-11-13T12:01:31.904323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'veloz': 1,\n",
       " 'raposa': 2,\n",
       " 'marrom': 3,\n",
       " 'saltou': 4,\n",
       " 'sobre': 5,\n",
       " 'o': 6,\n",
       " 'cachorro': 7,\n",
       " 'preguiçoso': 8}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Vocabulary from the sentence\n",
    "\n",
    "vocab = {}\n",
    "\n",
    "# For each token in the setence we save in our vocabulary\n",
    "for token in sentence:\n",
    "    if vocab.get(token) is None:\n",
    "        vocab[token] = len(vocab) \n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:03:10.048581Z",
     "start_time": "2020-11-13T12:03:10.044150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping to search eacth token in the sequence\n",
    "sentence_transformed = list(map(vocab.get, sentence))\n",
    "sentence_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:19:38.689811Z",
     "start_time": "2020-11-13T12:19:38.686635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:20:12.490061Z",
     "start_time": "2020-11-13T12:20:12.485079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating One Hot Encoding\n",
    "one_hot = np.eye(len(vocab), dtype=np.int)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:20:37.658142Z",
     "start_time": "2020-11-13T12:20:37.651316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n"
     ]
    }
   ],
   "source": [
    "print(vocab['a'], vocab['raposa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:22:15.230209Z",
     "start_time": "2020-11-13T12:22:15.227017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O Indice do Token a no vocabulario: 0\n",
      "O Vetor One-Hot Encoding: [1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# One-hot enconding to token \"a\"\n",
    "print(\"\\nO Indice do Token a no vocabulario:\", vocab['a'])\n",
    "print(\"O Vetor One-Hot Encoding:\", one_hot[vocab['a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:22:35.167636Z",
     "start_time": "2020-11-13T12:22:35.163657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O Indice do Token raposa no vocabulario: 2\n",
      "O Vetor One-Hot Encoding: [0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# One-hot enconding to token \"raposa\"\n",
    "print(\"\\nO Indice do Token raposa no vocabulario:\", vocab['raposa'])\n",
    "print(\"O Vetor One-Hot Encoding:\", one_hot[vocab['raposa']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Statistical Semantics Hypothesis we can from a word transform its meaning in a numerical vector. And similar vector has probably the same meaning, what means that the distance between to vectors will be less.\n",
    "\n",
    "We can measure the distance using Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:29:21.331200Z",
     "start_time": "2020-11-13T12:29:21.328106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to measure the distance\n",
    "def cos_similarity(x,y):\n",
    "    return (np.dot(x,y) / (np.linalg.norm(x) * np.linalg.norm(y))).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:31:53.239948Z",
     "start_time": "2020-11-13T12:31:53.234902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'veloz', 'raposa', 'marrom', 'saltou', 'sobre', 'o', 'cachorro', 'preguiçoso']\n"
     ]
    }
   ],
   "source": [
    "# Tokens in Sentence\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:32:05.776938Z",
     "start_time": "2020-11-13T12:32:05.774358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# One-hot matrix\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:32:57.419117Z",
     "start_time": "2020-11-13T12:32:57.416211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0] [0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Defining two words as one-hot vector\n",
    "\n",
    "palavra1 = one_hot[vocab['raposa']]\n",
    "palavra2 = one_hot[vocab['cachorro']]\n",
    "\n",
    "print(palavra1, palavra2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:33:28.931405Z",
     "start_time": "2020-11-13T12:33:28.913468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Similarity using Cosine Similarity\n",
    "cos_similarity(palavra1, palavra2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the distance is zero. Because the vectors used are sparse, we need transform to density vectors. Using:\n",
    "\n",
    "$$w_i = t_i \\cdot W , \\quad where\\ t_i = [0, \\cdots, \\underset{i\\text{-}th\\ index}{1}, \\cdots, 0],\\ len(t_i)=\\vert V \\vert$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:36:28.273560Z",
     "start_time": "2020-11-13T12:36:28.268801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "# Vector Space Shape\n",
    "dim = 5\n",
    "\n",
    "# Creating matrix (vector space) with random values from our vocabulary\n",
    "W = np.random.rand(len(vocab), dim).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:37:05.873229Z",
     "start_time": "2020-11-13T12:37:05.868725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vector Space to all tokens, initial values of weights\n",
      "[[0.173 0.565 0.755 0.56  0.572]\n",
      " [0.037 0.409 0.967 0.994 0.685]\n",
      " [0.068 0.875 0.22  0.391 0.498]\n",
      " [0.597 0.844 0.717 0.868 0.934]\n",
      " [0.524 0.909 0.417 0.332 0.331]\n",
      " [0.572 0.008 0.341 0.587 0.677]\n",
      " [0.517 0.348 0.029 0.391 0.292]\n",
      " [0.6   0.389 0.342 0.834 0.439]\n",
      " [0.693 0.024 0.439 0.471 0.467]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVector Space to all tokens, initial values of weights\")\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:39:02.459932Z",
     "start_time": "2020-11-13T12:39:02.455173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.068 0.875 0.22  0.391 0.498]\n",
      "[0.6   0.389 0.342 0.834 0.439]\n"
     ]
    }
   ],
   "source": [
    "# Transforming one-hot in density matrix (tokens: raposa and cachorro)\n",
    "\n",
    "resultado1 = np.dot(palavra1, W)\n",
    "print(resultado1)\n",
    "\n",
    "resultado2 = np.dot(palavra2, W)\n",
    "print(resultado2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:40:15.734216Z",
     "start_time": "2020-11-13T12:40:15.731001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The similarity between raposa and cachorro: 0.73615\n"
     ]
    }
   ],
   "source": [
    "# Calculating similarity\n",
    "\n",
    "similarity1 = cos_similarity(resultado1, resultado2)\n",
    "print(\"\\nThe similarity between raposa and cachorro:\", similarity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PyTorch to Calculate Similarity: Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:43:17.582689Z",
     "start_time": "2020-11-13T12:43:17.579519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Índices das palavras \"raposa\" e \"cachorro\" é [2, 7]\n"
     ]
    }
   ],
   "source": [
    "# Obtém os índices das palavras que queremos comparar\n",
    "idxes = [np.argmax(v) for v in [palavra1, palavra2]]\n",
    "print('\\nÍndices das palavras \"raposa\" e \"cachorro\" é {}'.format(idxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:44:23.598035Z",
     "start_time": "2020-11-13T12:44:23.595366Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_layer = nn.Embedding(len(vocab), dim, _weight = torch.FloatTensor(W))  \n",
    "idxes_tensor = torch.LongTensor(idxes)\n",
    "embeded = embed_layer(idxes_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:45:02.300338Z",
     "start_time": "2020-11-13T12:45:02.295634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.1730, 0.5650, 0.7550, 0.5600, 0.5720],\n",
      "        [0.0370, 0.4090, 0.9670, 0.9940, 0.6850],\n",
      "        [0.0680, 0.8750, 0.2200, 0.3910, 0.4980],\n",
      "        [0.5970, 0.8440, 0.7170, 0.8680, 0.9340],\n",
      "        [0.5240, 0.9090, 0.4170, 0.3320, 0.3310],\n",
      "        [0.5720, 0.0080, 0.3410, 0.5870, 0.6770],\n",
      "        [0.5170, 0.3480, 0.0290, 0.3910, 0.2920],\n",
      "        [0.6000, 0.3890, 0.3420, 0.8340, 0.4390],\n",
      "        [0.6930, 0.0240, 0.4390, 0.4710, 0.4670]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Values weights of embeded layer\n",
    "print(embed_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:45:27.344479Z",
     "start_time": "2020-11-13T12:45:27.341204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0680, 0.8750, 0.2200, 0.3910, 0.4980],\n",
      "        [0.6000, 0.3890, 0.3420, 0.8340, 0.4390]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Vector Embeded to 'raposa' and 'cachorro'\n",
    "print(embeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:46:56.995482Z",
     "start_time": "2020-11-13T12:46:56.993147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying Embedding to one-hot vectors\n",
    "palavra1 = embed_layer.weight[vocab.get('raposa')]\n",
    "palavra2 = embed_layer.weight[vocab.get('cachorro')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:48:15.688819Z",
     "start_time": "2020-11-13T12:48:15.685694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7361, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate Similarity\n",
    "similarity2 = F.cosine_similarity(palavra1, palavra2, dim=0)\n",
    "print(similarity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Both Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T12:48:48.254915Z",
     "start_time": "2020-11-13T12:48:48.251615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73615 tensor(0.7361, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(similarity1, similarity2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
